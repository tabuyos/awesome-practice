# [Redis](https://wylong.top/redis/)

## 参考

- Redis 官网：https://redis.io/
- Redis 在线测试：http://try.redis.io/
- Redis 命令参考：http://doc.redisfans.com/

## 什么是 Redis

`Redis` 是一个开源(BSD许可)的, 是一个高性能的 key-value 数据库.

内存中的数据结构存储系统, 它可以用作数据库, 缓存和消息中间件. 它支持多 种类型的数据结构, 如 字符串(strings), 散列(hashes),  列表(lists),  集合(sets),  有序集合(sorted sets)等.

`Redis` 与其他 `key-value` 缓存产品有以下三个特点: 

- Redis支持数据的持久化, 可以将内存中的数据保存在磁盘中, 重启的时候可以再次加载进行使用.
- Redis不仅仅支持简单的key-value类型的数据, 同时还提供list, set, zset, hash等数据结构的存储.
- Redis支持数据的备份, 即master-slave模式的数据备份.

## Windows安装 sentinel

```shell
# config
port 26379
daemonize yes
sentinel myid 91802ce2f29692bcc17f63a65a5b8bc29fb1c00e
sentinel deny-scripts-reconfig yes
sentinel monitor mymaster 127.0.0.1 6379 1
sentinel down-after-milliseconds mymaster 15000
sentinel failover-timeout mymaster 80000
# bind 172.26.5.247
# Generated by CONFIG REWRITE
dir "E:\\opt\\Redis"
sentinel auth-pass mymaster admin
sentinel config-epoch mymaster 0
sentinel leader-epoch mymaster 203
sentinel current-epoch 203
protected-mode no

# register windows service
redis-server --service-install --service-name Redis-Sentinel sentinel.conf --sentinel
```



## Redis与其他key-value存储有什么不同(优点)？

- Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。
- Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。

## Redis和memcached和mysql之间的区别

![img](redis-intro/01-redis与其他数据库区别.jpg)

## redis作为数据库和作为缓存的选择，线上怎么优雅的使用redis

**简介：redis作为数据库和作为内存缓存的两种使用方法**

- redis作为数据库的使用有什么优缺点
  - 优点
    - 没有Scheme约束，数据结构的变更相对容易，一开始确定数据类型， 抗压能力强，性能极高，10万/qps
  - 缺点
    - 没有索引，没有外键，缺少int/date等基本数据类型，多条件查询需要通过集合内联(sinter,zinterstore) 和连接间接实现开发效率低，可维护性不佳
- redis作为缓存的使用，搭配数据库使用的两种方案
  - jedis整合使用方案 set key,value ["11","22"] 第一层在缓存进行查询，如果得到数据则直接返回， 第二层在数据库进行查询，并且刷新缓存，方便下次查询 ["33,"44"]
  - 作为mybatis/hibernate二级缓存使用方案，一级缓存：sqlSession，进程缓存，单次链接有效

## Redis消息订阅发布

**简介：redis消息订阅发布讲解，基础使用**

- 作用：发布订阅类似于信息管道，用来进行系统之间消息解耦，类似于mq，rabbitmq、rocketmq、kafka、activemq主要有消息发布者和消息订阅者。比如运用于：订单支付成功，会员系统加积分、钱包进行扣钱操作、发货系统（下发商品）

- PUBLISH 将信息message发送到指定的频道channel。返回收到消息的客户端数量
- SUBSCRIBE 订阅给指定频道的信息
- UNSUBSCRIBE 取消订阅指定的频道，如果不指定，则取消订阅所有的频道。
- redis的消息订阅发布和mq对比？

  答：redis发布订阅功能比较薄弱但比较轻量级

   mq消息持久化，数据可靠性比较差

   无后台功能（mq通常都有个后台管理平台）

   可msgId、msgKey进行查询消息

## 数据类型

### String字符串(key-value)数据类型

String是最常用的一种数据类型，普通的key/value存储都可以归为此类。

常用命令：

- set/get
  - 设置key对应的值为String类型的value
  - 获取key对应的值
- mget
  - 批量获取多个key的值，如果可以不存在则返回nil
- incr && incrby
  - incr对key对应的值进行加加操作，并返回新的值;incrby加指定值
- setnx
  - 设置key对应的值为String类型的value，如果key已经存在则返回0
- setex
  - 设置key对应的值为String类型的value，并设定有效期
- 其他命令
  - getrange 获取key对应value的子字符串
  - mset 批量设置多个key的值，如果成功表示所有值都被设置，否则返回0表示没有任何值被设置
  - msetnx，同mset，不存在就设置，不会覆盖已有的key
  - getset 设置key的值，并返回key旧的值
  - append：给指定key的value追加字符串，并返回新字符串的长度

> 备注：redis String命令的使用实战，记住1、3、5、6这几个重要命令



------

### Hash类型讲解

Redis hash 是一个 string 类型的 field（字段） 和 value（值） 的映射表，hash 特别适合用于存储对象。

Redis 中每个 hash 可以存储 232 - 1 键值对（40多亿）。

常用命令：

- Hash是一个String类型的field和value之间的映射表
- redis的Hash数据类型的key（hash表名称）对应的value实际的内部存储结构为一个HashMap
- Hash特别适合存储对象
- 相对于把一个对象的每个属性存储为String类型，将整个对象存储在Hash类型中会占用更少内存。
- 所存储的成员较少时数据存储为zipmap，当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。
- 运用场景： 如用一个对象来存储用户信息，商品信息，订单信息等等。

- Hash命令讲解
  - hset——设置key对应的HashMap中的field的value
  - hget——获取key对应的HashMap中的field的value
  - hgetall——获取key对应的HashMap中的所有field的value
  - hlen--返回key对应的HashMap中的field的数量

------

### List列表类型讲解

Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）

一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。

常用命令：

- lpush——在key对应的list的头部添加一个元素
- lrange——获取key对应的list的指定下标范围的元素，-1表示获取所有元素
- lpop——从key对应的list的尾部删除一个元素，并返回该元素
- rpush——在key对应的list的尾部添加一个元素
- rpop——从key对应的list的尾部删除一个元素，并返回该元素

------

### Set类型讲解

Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。

Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。

集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。

常用命令：

- sadd——在key对应的set中添加一个元素
- smembers——获取key对应的set的所有元素
- spop——随机返回并删除key对应的set中的一个元素
- suion——求给定key对应的set并集
- sinter——求给定key对应的set交集

------

### SortSet类型讲解

Redis 有序集合和集合一样也是 string 类型元素的集合,且不允许重复的成员。

不同的是每个元素都会关联一个 double 类型的分数。redis 正是通过分数来为集合中的成员进行从小到大的排序。

有序集合的成员是唯一的,但分数(score)却可以重复。

集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 2^32 - 1 (4294967295, 每个集合可存储40多亿个成员)。

set的基础增加顺序score，再根据score进行排序 实战：通过sortset实现排行榜

- zadd ——在key对应的zset中添加一个元素
- zrange——获取key对应的zset中指定范围的元素，-1表示获取所有元素
- zrem——删除key对应的zset中的一个元素
- zrangebyscore——返回有序集key中，指定分数范围的元素列表,排行榜中运用
- zrank——返回key对应的zset中指定member的排名。其中member按score值递增(从小到大）； 排名以0为底，也就是说，score值最小的成员排名为0,排行榜中运用

**set和sortset对比**

- set是通过hashmap存储，key对应set的元素，value是空对象
- sortset是怎么存储并实现排序的呢，hashmap存储，还加了一层跳跃表 跳跃表：相当于双向链表，在其基础上添加前往比当前元素大的跳转链接

##  传统关系型数据库事务与Redis事务

### 一、 深入浅出剖析传统关系型数据库事务

**简介：通过类比法进行学习可以增强知识掌握程度，讲解事务概要和事务隔离级别**

- 一个数据库事务通常包含了一个序列的对数据库的读/写操作。它的存在包含有以下两个目的：
  - 为数据库操作序列提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。
  - 当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。

- 事务的ACID四大特性
  - 原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行
  - 一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束
  - 隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行
  - 持久性（Durability）：已被提交的事务对数据库的修改应该永久保存在数据库中

- 事务隔离机制
  - 语法：set global transaction isolation level read uncommitted;
  - 种类：read uncommitted、read committed、repeatable read、serializable

### 二、浅谈mysql事务隔离机制和MVCC

- redis事务隔离机制可重复读讲解（repeatable read）
- InnoDB MVCC多版本并发控制功能讲解
  - 在每一行数据中额外保存两个隐藏的列：当前行创建时的版本号和删除时的版本号（可能为空，其实还有一列称为回滚指针，用于事务回滚，不在本文范畴）。这里的版本号并不是实际的时间值，而是系统版本号。每开始新的事务，系统版本号都会自动递增。事务开始时刻的系统版本号会作为事务的版本号， 用来和查询每行记录的版本号进行比较
- 图解InnoDB MVCC的组成和原理

### 三、redis事务机制

**简介：讲解redis事务基本命令，分析redis事务的基本原理**

- MULTI 与 EXEC命令
  - 以 MULTI 开始一个事务，然后将多个命令入队到事务中， 最后由 EXEC 命令触发事务， 一并执行事务中的所有命令
- DISCARD命令
  - DISCARD 命令用于取消一个事务， 它清空客户端的整个事务队列， 然后将客户端从事务状态调整回非事务状态， 最后返回字符串 OK 给客户端， 说明事务已被取消
- WATCH命令
  - WATCH 命令用于在事务开始之前监视任意数量的键： 当调用 EXEC 命令执行事务时， 如果任意一个被监视的键已经被其他客户端修改了， 那么整个事务不再执行， 直接返回失败。

###  四、redis事务与传统关系型事务的比较

**简介：讲解redis事务ACID**

- 原子性（Atomicity）
  - 单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。如果一个事务队列中的所有命令都被成功地执行，那么称这个事务执行成功
- 一致性（Consistency）
  - 入队错误
    - 在命令入队的过程中，如果客户端向服务器发送了错误的命令，比如命令的参数数量不对，等等， 那么服务器将向客户端返回一个出错信息， 并且将客户端的事务状态设为 REDIS_DIRTY_EXEC 。
  - 执行错误
    - 如果命令在事务执行的过程中发生错误，比如说，对一个不同类型的 key 执行了错误的操作， 那么 Redis 只会将错误包含在事务的结果中， 这不会引起事务中断或整个失败，不会影响已执行事务命令的结果，也不会影响后面要执行的事务命令， 所以它对事务的一致性也没有影响

- 隔离性（Isolation）
  - WATCH 命令用于在事务开始之前监视任意数量的键： 当调用 EXEC 命令执行事务时， 如果任意一个被监视的键已经被其他客户端修改了， 那么整个事务不再执行， 直接返回失败
- 持久性（Durability）
  - 因为事务不过是用队列包裹起了一组 Redis 命令，并没有提供任何额外的持久性功能，所以事务的持久性由 Redis 所使用的持久化模式决定

##  redis实现分布式集群环境session共享

- cookie与session

  - Cookie是什么？ Cookie 是一小段文本信息，伴随着用户请求和页面在 Web 服务器和浏览器之间传递。Cookie 包含每次用户访问站点时

    Web 应用程序都可以读取的信息，我们可以看到在服务器写的cookie，会通过响应头Set-Cookie的方式写入到浏览器

  - HTTP协议是无状态的，并非TCP一样进行三次握手，对于一个浏览器发出的多次请求，WEB服务器无法区分是不是来源于同一个浏览器。所以服务器为了区分这个过程会通过一个 sessionid来区分请求，而这个sessionid是怎么发送给服务端的呢。cookie相对用户是不可见的，用来保存这个sessionid是最好不过了

- redis实现分布式集群配置过程
  - org.springframework.session spring-session-data-redis
  - @EnableRedisHttpSession 开启redis session缓存
  - maxInactiveIntervalInSeconds指定缓存的时间 spring:session:sessions:expires:+‘sessionId’的过期时间
- 验证过程
  - 打开隐身模式清空cookie来验证缓存的时间

> 分布式系统，现在主流采用token的方式作为身份验证，JWT的方案目前比较流行

## 分布式锁

### Redis分布式锁的使用场景

分布式锁是BATJ最常见的Redis面试题，对分布式锁的掌握，多场景下不同版本分布锁的掌握显得尤为关键

- 分布式锁是什么

  - 分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现
  - 如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往通过互斥来防止彼此干扰。

- 分布锁设计目的

  可以保证在分布式部署的应用集群中，同一个方法在同一操作只能被一台机器上的一个线程执行。

- 设计要求

  - 这把锁要是一把可重入锁（避免死锁）
  - 这把锁有高可用的获取锁和释放锁功能
  - 这把锁获取锁和释放锁的性能要好…

- 分布锁实现方案分析

  - 获取锁的时候，使用 setnx(SETNX key val:当且仅当 key 不存在时，set 一个 key 为 val 的字符串，返回 1;
  - 若 key 存在，则什么都不做，返回 【0】加锁，锁的 value 值为当前占有锁服务器内网IP编号拼接任务标识
  - 在释放锁的时候进行判断。并使用 expire 命令为锁添 加一个超时时间，超过该时间则自动释放锁。
  - 返回1则成功获取锁。还设置一个获取的超时时间， 若超过这个时间则放弃获取锁。setex（key,value,expire）过期以秒为单位
  - 释放锁的时候，判断是不是该锁（即Value为当前服务器内网IP编号拼接任务标识），若是该锁，则执行 delete 进行锁释放

**保证setnx和setex两个操作的原子性** - 必须都成功才可以。

- 采用Lua脚本
- Redis从2.6之后支持setnx、setex连用

### Lua脚本实现Redis分布式锁

- Lua简介
  - 从 Redis 2.6.0 版本开始，通过内置的 Lua 解释器，可以使用 EVAL 命令对 Lua 脚本进行求值。
  - Redis 使用单个 Lua 解释器去运行所有脚本，并且， Redis 也保证脚本会以原子性(atomic)的方式执行：当某个脚本正在运行的时候，不会有其他脚本或 Redis 命令被执行。这和使用 MULTI / EXEC 包围的事务很类似。在其他别的客户端看来，脚本的效果(effect)要么是不可见的(not visible)，要么就是已完成的(already completed)。
- Lua脚本配置流程
  - 1、在resource目录下面新增一个后缀名为.lua结尾的文件
  - 2、编写lua脚本
  - 3、传入lua脚本的key和arg
  - 4、调用redisTemplate.execute方法执行脚本
- Lua脚本结合RedisTempalte示例

lua脚本

```lua
local lockKey = KEYS[1]
local lockValue = KEYS[2]

-- setnx info
local result_1 = redis.call('SETNX', lockKey, lockValue)
if result_1 == true
then
local result_2= redis.call('SETEX', lockKey,3600, lockValue)
return result_1
else
return result_1
end
```

java代码

```java
    public void lockJob() {
        String lock = LOCK_PREFIX + "LockNxExJob";
        boolean luaRet = false;
        try {
            luaRet = luaExpress(lock,getHostIp());//getHostIp-获取本机内网IP地址
            //获取锁失败
            if (!luaRet) {
                String value = (String) redisService.genValue(lock);
                return;
            } else {
                //获取锁成功
                Thread.sleep(5000);
            }
        } catch (Exception e) {
            logger.error("lock error", e);
        } finally {
            if (luaRet) {
                // 不能直接释放锁，会有如下问题
                redisService.remove(lock);
                // 释放锁的时候，有可能因为持锁之后方法执行时间大于锁的有效期
                // 此时有可能已经被另外一个线程持有锁，所以不能直接删除,否则A解锁了B持有的锁
                // 解决办法：
                // 解锁只能解自己的锁(根据锁的key和value综合判断解锁)
                // 先根据key获得value，判断value是否是自己的锁，再做删除
            }
        }
    }


    /**
     * 获取lua结果
     * @param key
     * @param value
     * @return
     */
    public Boolean luaExpress(String key,String value) {
        lockScript = new DefaultRedisScript<Boolean>();
        lockScript.setScriptSource(
                new ResourceScriptSource(new ClassPathResource("add.lua")));
        lockScript.setResultType(Boolean.class);
        // 封装参数
        List<Object> keyList = new ArrayList<Object>();
        keyList.add(key);
        keyList.add(value);
        Boolean result = (Boolean) redisTemplate.execute(lockScript, keyList);
        return result;
    }
```

### RedisConnection实现分布式锁

**采用redisTemplate操作redisConnection 实现setnx和setex两个命令连用**

- redisTemplate本身有没通过valueOperation实现分布式锁
  - 问题探索： Spring Data Redis提供了与Java客户端包的集成服务，比如Jedis, JRedis等 通过getNativeConnection的方式可以解决问题吗？
- Spring Data Redis提供了与Java客户端包的集成服务，比如Jedis, JRedis等

代码示例：

```java
    /**
     * 获得锁 setnx、setex连用
     * @param key
     * @param expire
     * @return
     */
    public boolean setLock(String key, long expire) {
        try {
            Boolean result = redisTemplate.execute(new RedisCallback<Boolean>() {
                @Override
                public Boolean doInRedis(RedisConnection connection) throws DataAccessException {
                    return connection.set(key.getBytes(), getHostIp().getBytes(), Expiration.seconds(expire) ,RedisStringCommands.SetOption.ifAbsent());
                }
            });
            return result;
        } catch (Exception e) {
            logger.error("set redis occured an exception", e);
        }
        return false;
    }
```

------

### 实战操作采用lua脚本做高可用分布式锁的优化

**简介：高可用分布式锁的优化点分析**

- 解锁的流程分析

  当某个锁需要持有的时间小于锁超时时间时会出现两个进程同时执行任务的情况， 这时候如果进程没限制只有占有这把锁的人才能解锁的原则就会出现， A解了B的锁。

- 采用lua脚本做解锁流程优化讲解

![img](redis-intro/07-分布式锁优化分析.png)

lua脚本释放锁示例：

lua脚步也可以直接定义在java代码中使用

```java
    public static final String UNLOCK_LUA;

    static {
        StringBuilder sb = new StringBuilder();
        sb.append("local lockKey = KEYS[1] ");
        sb.append("local lockValue = KEYS[2] ");
        sb.append("local result_1 = redis.call('get', lockKey) ");
        sb.append("if result_1 == lockValue ");
        sb.append("then ");
        sb.append("local result_2= redis.call('del', lockKey) ");
        sb.append("return result_2 ");
        sb.append("else ");
        sb.append("return false ");
        sb.append("end ");
        UNLOCK_LUA = sb.toString();
    }

    /**
     * 使用Lua脚本释放锁
     * @param key
     * @param value
     * @return
     */
    private boolean releaseLock(String key, String value) {
        // 封装参数
        List<Object> keyList = new ArrayList<Object>();
        keyList.add(key);
        keyList.add(value);

        lockScript = new DefaultRedisScript<Boolean>();
        lockScript.setScriptText(UNLOCK_LUA);
        lockScript.setResultType(Boolean.class);

        Boolean result = (Boolean) redisTemplate.execute(lockScript, keyList);
        return result;
    }

    /**
    * 获得锁-改造部分为finally中的释放方法
    */
    public void lockJob() {
        String lock = LOCK_PREFIX + "LockNxExJob";
        boolean luaRet = false;
        try {
            luaRet = luaExpress(lock,getHostIp());//getHostIp-获取本机内网IP地址
            //获取锁失败
            if (!luaRet) {
                String value = (String) redisService.genValue(lock);
                return;
            } else {
                //获取锁成功
                Thread.sleep(5000);
            }
        } catch (Exception e) {
            logger.error("lock error", e);
        } finally {
            if (luaRet) {
                // 不能直接释放锁，会有如下问题
                // 释放锁的时候，有可能因为持锁之后方法执行时间大于锁的有效期
                // 此时有可能已经被另外一个线程持有锁，所以不能直接删除,否则A解锁了B持有的锁
                // 解决办法：
                // 解锁只能解自己的锁(根据锁的key和value综合判断解锁)
                // 先根据key获得value，判断value是否是自己的锁，再做删除
                // redisService.remove(lock);
                releaseLock(lock,getHostIp());
            }
        }
    }
```

- 遗留问题
  - 锁的过期时间，如何实现锁的自动续期 或者 避免业务执行时间过长，锁过期了？
    - 原生方式的话，一般把锁的过期时间设置的久一点：比如10分钟时间

------

### redis分布式锁最佳实现 redisson

**redis**官⽅推荐**-**分布式锁最佳实践 redisson

------

### Redis布式锁总结

- 问题1： 1、什么是分布式锁？

  - 首先，为了确保分布式锁可用，我们至少要确保锁的实现同时满足以下三个条件：
    - 互斥性。在任意时刻，只有一个客户端能持有锁。
    - 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。
    - 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了

- - 从 Redis 2.6.0 版本开始，通过内置的 Lua 解释器，可以使用 EVAL 命令对 Lua 脚本进行求值。
  - Redis 使用单个 Lua 解释器去运行所有脚本，并且， Redis 也保证脚本会以原子性(atomic)的方式执行：当某个脚本正在运行的时候，不会有其他脚本或 Redis 命令被执行。这和使用 MULTI / EXEC 包围的事务很类似。在其他别的客户端看来，脚本的效果(effect)要么是不可见的(not visible)，要么就是已完成的(already completed)。

- 问题2：怎么实现分布式锁

  - 实现分布式锁的方案大概有两种
    - 采用lua脚本操作分布式锁
    - 采用setnx、setex命令连用的方式实现分布式锁

- 问题3：

  - 解锁需要注意什么

    **解铃还须系铃人**。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了





# [聊聊分布式锁——Redis和Redisson的方式-51CTO.COM](https://www.51cto.com/article/682636.html)

### 一、什么是分布式锁

- 分布式~~锁，要这么念，首先得是『分布式』，然后才是『锁』

分布式：这里的分布式指的是分布式系统，涉及到好多技术和理论，包括CAP 理论、分布式存储、分布式事务、分布式锁...

分布式系统是由一组通过网络进行通信、为了完成共同的任务而协调工作的计算机节点组成的系统。

分布式系统的出现是为了用廉价的、普通的机器完成单个计算机无法完成的计算、存储任务。其目的是利用更多的机器，处理更多的数据。

- 锁：对对，就是你想的那个，Javer 学的第一个锁应该就是 synchronized

Java 初级面试问题，来拼写下 赛克瑞纳挨日的

从锁的使用场景有来看下边这 3 种锁：

线程锁：synchronized 是用在方法或代码块中的，我们把它叫『线程锁』，线程锁的实现其实是靠线程之间共享内存实现的，说白了就是内存中的一个整型数，有空闲、上锁这类状态，比如 synchronized 是在对象头中的 Mark Word 有个锁状态标志，Lock 的实现类大部分都有个叫 volatile int state 的共享变量来做状态标志。

进程锁：为了控制同一操作系统中多个进程访问某个共享资源，因为进程具有独立性，各个进程无法访问其他进程的资源，因此无法通过 synchronized 等线程锁实现进程锁。比如说，我们的同一个 linux 服务器，部署了好几个 Java 项目，有可能同时访问或操作服务器上的相同数据，这就需要进程锁，一般可以用『文件锁』来达到进程互斥。

分布式锁：随着用户越来越多，我们上了好多服务器，原本有个定时给客户发邮件的任务，如果不加以控制的话，到点后每台机器跑一次任务，客户就会收到 N 条邮件，这就需要通过分布式锁来互斥了。

书面解释：分布式锁是控制分布式系统或不同系统之间共同访问共享资源的一种锁实现，如果不同的系统或同一个系统的不同主机之间共享了某个资源时，往往需要互斥来防止彼此干扰来保证一致性。

知道了什么是分布式锁，接下来就到了技术选型环节

### 二、分布式锁要怎么搞

要实现一个分布式锁，我们一般选择集群机器都可以操作的外部系统，然后各个机器都去这个外部系统申请锁。

这个外部系统一般需要满足如下要求才能胜任：

1. 互斥：在任意时刻，只能有一个客户端能持有锁。
2. 防止死锁：即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。所以锁一般要有一个过期时间。
3. 独占性：解铃还须系铃人，加锁和解锁必须是同一个客户端，一把锁只能有一把钥匙，客户端自己的锁不能被别人给解开，当然也不能去开别人的锁。
4. 容错：外部系统不能太“脆弱”，要保证外部系统的正常运行，客户端才可以加锁和解锁。

我觉得可以这么类比：

好多商贩要租用某个仓库，同一时刻，只能给一个商贩租用，且只能有一把钥匙，还得有固定的“租期”，到期后要回收的，当然最重要的是仓库门不能坏了，要不锁都锁不住。这不就是分布式锁吗?

感慨自己真是个爱技术爱生活的程序猿~~

其实锁，本质上就是用来进行防重操作的(数据一致性)，像查询这种幂等操作，就不需要费这劲

直接上结论：

分布式锁一般有三种实现方式：1. 数据库乐观锁;2. 基于 Redis 的分布式锁;3. 基于 ZooKeeper 的分布式锁。

但为了追求更好的性能，我们通常会选择使用 Redis 或 Zookeeper 来做。

想必也有喜欢问为什么的同学，那数据库客观锁怎么就性能不好了?

使用数据库乐观锁，包括主键防重，版本号控制。但是这两种方法各有利弊。

使用主键冲突的策略进行防重，在并发量非常高的情况下对数据库性能会有影响，尤其是应用数据表和主键冲突表在一个库的时候，表现更加明显。还有就是在 MySQL 数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象，比较好的办法是在程序中生产主键进行防重。

使用版本号策略

这个策略源于 MySQL 的 MVCC 机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断 SQL 每次进行判断。

第三趴，编码

### 三、基于 Redis 的分布式锁

其实 Redis 官网已经给出了实现：https://redis.io/topics/distlock，说各种书籍和博客用了各种手段去用 Redis 实现分布式锁，建议用 Redlock 实现，这样更规范、更安全。我们循序渐进来看

我们默认指定大家用的是 Redis 2.6.12 及更高的版本，就不再去讲 setnx、expire 这种了，直接 set 命令加锁



```shell
set key value[expiration EX seconds|PX milliseconds] [NX|XX] 
```

eg:



```shell
SET resource_name my_random_value NX PX 30000 
```

SET 命令的行为可以通过一系列参数来修改

- EX second ：设置键的过期时间为 second 秒。SET key value EX second 效果等同于 SETEX key second value 。
- PX millisecond ：设置键的过期时间为 millisecond 毫秒。SET key value PX millisecond 效果等同于 PSETEX key millisecond value 。
- NX ：只在键不存在时，才对键进行设置操作。SET key value NX 效果等同于 SETNX key value 。
- XX ：只在键已经存在时，才对键进行设置操作。

这条指令的意思：当 key——resource_name 不存在时创建这样的key，设值为 my_random_value，并设置过期时间 30000 毫秒。

别看这干了两件事，因为 Redis 是单线程的，这一条指令不会被打断，所以是原子性的操作。

Redis 实现分布式锁的主要步骤：

1. 指定一个 key 作为锁标记，存入 Redis 中，指定一个 唯一的标识 作为 value。
2. 当 key 不存在时才能设置值，确保同一时间只有一个客户端进程获得锁，满足 互斥性 特性。
3. 设置一个过期时间，防止因系统异常导致没能删除这个 key，满足 防死锁 特性。
4. 当处理完业务之后需要清除这个 key 来释放锁，清除 key 时需要校验 value 值，需要满足 解铃还须系铃人 。

设置一个随机值的意思是在解锁时候判断 key 的值和我们存储的随机数是不是一样，一样的话，才是自己的锁，直接 del 解锁就行。

当然这个两个操作要保证原子性，所以 Redis 给出了一段 lua 脚本(Redis 服务器会单线程原子性执行 lua 脚本，保证 lua 脚本在处理的过程中不会被任意其它请求打断。)：



```lua
if redis.call("get",KEYS[1]) == ARGV[1] then 
    return redis.call("del",KEYS[1]) 
else 
    return 0 
end 
```

### 问题：

我们先抛出两个问题思考：

获取锁时，过期时间要设置多少合适呢?

预估一个合适的时间，其实没那么容易，比如操作资源的时间最慢可能要 10 s，而我们只设置了 5 s 就过期，那就存在锁提前过期的风险。这个问题先记下，我们先看下 Javaer 要怎么在代码中用 Redis 锁。

容错性如何保证呢?

Redis 挂了怎么办，你可能会说上主从、上集群，但也会出现这样的极端情况，当我们上锁后，主节点就挂了，这个时候还没来的急同步到从节点，主从切换后锁还是丢了

带着这两个问题，我们接着看

### Redisson 实现代码

redisson 是 Redis 官方的分布式锁组件。GitHub 地址：https://github.com/redisson/redisson

Redisson 是一个在 Redis 的基础上实现的 Java 驻内存数据网格(In-Memory Data Grid)。它不仅提供了一系列的分布式的 Java 常用对象，还实现了可重入锁(Reentrant Lock)、公平锁(Fair Lock、联锁(MultiLock)、 红锁(RedLock)、 读写锁(ReadWriteLock)等，还提供了许多分布式服务。Redisson 提供了使用 Redis 的最简单和最便捷的方法。Redisson 的宗旨是促进使用者对 Redis 的关注分离(Separation of Concern)，从而让使用者能够将精力更集中地放在处理业务逻辑上。

redisson 现在已经很强大了，github 的 wiki 也很详细，分布式锁的介绍直接戳 Distributed locks and synchronizers

Redisson 支持单点模式、主从模式、哨兵模式、集群模式，只是配置的不同，我们以单点模式来看下怎么使用，代码很简单，都已经为我们封装好了，直接拿来用就好，详细的demo，我放在了 github: starfish-learn-redisson 上，这里就不一步步来了



```java
RLock lock = redisson.getLock("myLock"); 
```

RLock 提供了各种锁方法，我们来解读下这个接口方法，

注：代码为 3.16.2 版本，可以看到继承自 JDK 的 Lock 接口，和 Reddsion 的异步锁接口 RLockAsync(这个我们先不研究)

**RLock**

[![img](redis-intro/e58b4d4e86d5bc9b2e93a9a747f45690.jpg)](https://s3.51cto.com/oss/202109/17/e58b4d4e86d5bc9b2e93a9a747f45690.jpg)



```java
public interface RLock extends Lock, RLockAsync { 
 
    /** 
     * 获取锁的名字 
     */ 
    String getName(); 
     
    /** 
     * 这个叫终端锁操作，表示该锁可以被中断 假如A和B同时调这个方法，A获取锁，B为获取锁，那么B线程可以通过 
     * Thread.currentThread().interrupt(); 方法真正中断该线程 
     */ 
    void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException; 
 
    /** 
     * 这个应该是最常用的，尝试获取锁 
     * waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败 
     * leaseTime   锁的持有时间,超过这个时间锁会自动失效（值应设置为大于业务处理的时间，确保在锁有效期内业务能处理完） 
     */ 
    boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException; 
 
    /** 
     * 锁的有效期设置为 leaseTime，过期后自动失效 
     * 如果 leaseTime 设置为 -1, 表示不主动过期 
     */ 
    void lock(long leaseTime, TimeUnit unit); 
 
    /** 
     * Unlocks the lock independently of its state 
     */ 
    boolean forceUnlock(); 
 
    /** 
     * 检查是否被另一个线程锁住 
     */ 
    boolean isLocked(); 
 
    /** 
     * 检查当前线线程是否持有该锁 
     */ 
    boolean isHeldByCurrentThread(); 
   
     /** 
     *  这个就明了了，检查指定线程是否持有锁 
     */ 
    boolean isHeldByThread(long threadId); 
 
    /** 
     * 返回当前线程持有锁的次数 
     */ 
    int getHoldCount(); 
 
    /** 
     * 返回锁的剩余时间 
     * @return time in milliseconds 
     *          -2 if the lock does not exist. 
     *          -1 if the lock exists but has no associated expire. 
     */ 
    long remainTimeToLive(); 
     
} 
```

**Demo**

就是这么简单，Redisson 已经做好了封装，使用起来 so easy，如果使用主从、哨兵、集群这种也只是配置不同。

**原理**

看源码小 tips，最好是 fork 到自己的仓库，然后拉到本地，边看边注释，然后提交到自己的仓库，也方便之后再看，不想这么麻烦的，也可以直接看我的 Jstarfish/redisson

先看下 RLock 的类关系

[![img](redis-intro/1d833877375c841c46fc006776cd276f.jpg)](https://s2.51cto.com/oss/202109/17/1d833877375c841c46fc006776cd276f.jpg)

跟着源码，可以发现 RedissonLock 是 RLock 的直接实现，也是我们加锁、解锁操作的核心类

**加锁**

主要的加锁方法就下边这两个，区别也很简单，一个有等待时间，一个没有，所以我们挑个复杂的看(源码包含了另一个的绝大部分)



```java
boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException; 
void lock(long leaseTime, TimeUnit unit); 
```

**RedissonLock.tryLock**



```java
@Override 
public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException { 
    // 获取等锁的最长时间 
    long time = unit.toMillis(waitTime); 
    long current = System.currentTimeMillis(); 
    //取得当前线程id（判断是否可重入锁的关键） 
    long threadId = Thread.currentThread().getId(); 
    // 【核心点1】尝试获取锁，若返回值为null，则表示已获取到锁，返回的ttl就是key的剩余存活时间 
    Long ttl = tryAcquire(waitTime, leaseTime, unit, threadId); 
    if (ttl == null) { 
        return true; 
    } 
    // 还可以容忍的等待时长 = 获取锁能容忍的最大等待时长 - 执行完上述操作流程的时间 
    time -= System.currentTimeMillis() - current; 
    if (time <= 0) { 
        //等不到了，直接返回失败 
        acquireFailed(waitTime, unit, threadId); 
        return false; 
    } 
 
    current = System.currentTimeMillis(); 
    /** 
     * 【核心点2】 
     * 订阅解锁消息 redisson_lock__channel:{$KEY}，并通过await方法阻塞等待锁释放，解决了无效的锁申请浪费资源的问题： 
     * 基于信息量，当锁被其它资源占用时，当前线程通过 Redis 的 channel 订阅锁的释放事件，一旦锁释放会发消息通知待等待的线程进行竞争 
     * 当 this.await返回false，说明等待时间已经超出获取锁最大等待时间，取消订阅并返回获取锁失败 
     * 当 this.await返回true，进入循环尝试获取锁 
     */ 
    RFuture<RedissonLockEntry> subscribeFuture = subscribe(threadId); 
    //await 方法内部是用CountDownLatch来实现阻塞，获取subscribe异步执行的结果（应用了Netty 的 Future） 
    if (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) { 
        if (!subscribeFuture.cancel(false)) { 
            subscribeFuture.onComplete((res, e) -> { 
                if (e == null) { 
                    unsubscribe(subscribeFuture, threadId); 
                } 
            }); 
        } 
        acquireFailed(waitTime, unit, threadId); 
        return false; 
    } 
 
    // ttl 不为空，表示已经有这样的key了，只能阻塞等待 
    try { 
        time -= System.currentTimeMillis() - current; 
        if (time <= 0) { 
            acquireFailed(waitTime, unit, threadId); 
            return false; 
        } 
 
        // 来个死循环，继续尝试着获取锁 
        while (true) { 
            long currentTime = System.currentTimeMillis(); 
            ttl = tryAcquire(waitTime, leaseTime, unit, threadId); 
            if (ttl == null) { 
                return true; 
            } 
 
            time -= System.currentTimeMillis() - currentTime; 
            if (time <= 0) { 
                acquireFailed(waitTime, unit, threadId); 
                return false; 
            } 
 
            currentTime = System.currentTimeMillis(); 
 
           /** 
            * 【核心点3】根据锁TTL，调整阻塞等待时长； 
            * 1、latch其实是个信号量Semaphore，调用其tryAcquire方法会让当前线程阻塞一段时间，避免在while循环中频繁请求获锁； 
            *  当其他线程释放了占用的锁，会广播解锁消息，监听器接收解锁消息，并释放信号量，最终会唤醒阻塞在这里的线程 
            * 2、该Semaphore的release方法，会在订阅解锁消息的监听器消息处理方法org.redisson.pubsub.LockPubSub#onMessage调用； 
            */ 
            //调用信号量的方法来阻塞线程，时长为锁等待时间和租期时间中较小的那个 
            if (ttl >= 0 && ttl < time) { 
                subscribeFuture.getNow().getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); 
            } else { 
                subscribeFuture.getNow().getLatch().tryAcquire(time, TimeUnit.MILLISECONDS); 
            } 
 
            time -= System.currentTimeMillis() - currentTime; 
            if (time <= 0) { 
                acquireFailed(waitTime, unit, threadId); 
                return false; 
            } 
        } 
    } finally { 
        // 获取到锁或者抛出中断异常，退订redisson_lock__channel:{$KEY}，不再关注解锁事件 
        unsubscribe(subscribeFuture, threadId); 
    } 
} 
```

接着看注释中提到的 3 个核心点

**核心点1-尝试加锁：RedissonLock.tryAcquireAsync**



```java
private <T> RFuture<Long> tryAcquireAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId) { 
    RFuture<Long> ttlRemainingFuture; 
    // leaseTime != -1 说明没过期 
    if (leaseTime != -1) { 
        // 实质是异步执行加锁Lua脚本 
        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG); 
    } else { 
        // 否则，已经过期了,传参变为新的时间（续期后） 
        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime, 
                TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); 
    } 
    ttlRemainingFuture.onComplete((ttlRemaining, e) -> { 
        if (e != null) { 
            return; 
        } 
 
        // lock acquired 
        if (ttlRemaining == null) { 
            if (leaseTime != -1) { 
                internalLockLeaseTime = unit.toMillis(leaseTime); 
            } else { 
                // 续期 
                scheduleExpirationRenewal(threadId); 
            } 
        } 
    }); 
    return ttlRemainingFuture; 
} 
```

**异步执行加锁 Lua 脚本：RedissonLock.tryLockInnerAsync**



```java
<T> RFuture<T> tryLockInnerAsync(long waitTime, long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand<T> command) { 
    return evalWriteAsync(getRawName(), LongCodec.INSTANCE, command, 
            // 1.如果缓存中的key不存在，则执行 hincrby 命令(hincrby key UUID+threadId 1), 设值重入次数1 
            // 然后通过 pexpire 命令设置锁的过期时间(即锁的租约时间) 
            // 返回空值 nil ，表示获取锁成功 
            "if (redis.call('exists', KEYS[1]) == 0) then " + 
                    "redis.call('hincrby', KEYS[1], ARGV[2], 1); " + 
                    "redis.call('pexpire', KEYS[1], ARGV[1]); " + 
                    "return nil; " + 
                    "end; " + 
                    // 如果key已经存在，并且value也匹配，表示是当前线程持有的锁，则执行 hincrby 命令，重入次数加1，并且设置失效时间 
                    "if (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then " + 
                    "redis.call('hincrby', KEYS[1], ARGV[2], 1); " + 
                    "redis.call('pexpire', KEYS[1], ARGV[1]); " + 
                    "return nil; " + 
                    "end; " + 
                    //如果key已经存在，但是value不匹配，说明锁已经被其他线程持有，通过 pttl 命令获取锁的剩余存活时间并返回，至此获取锁失败 
                    "return redis.call('pttl', KEYS[1]);", 
            Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId)); 
}
```

- KEYS[1] 就是 Collections.singletonList(getName())，表示分布式锁的key;
- ARGV[1] 就是internalLockLeaseTime，即锁的租约时间(持有锁的有效时间)，默认30s;
- ARGV[2] 就是getLockName(threadId)，是获取锁时set的唯一值 value，即UUID+threadId

看门狗续期：RedissonBaseLock.scheduleExpirationRenewal



```java
// 基于线程ID定时调度和续期 
protected void scheduleExpirationRenewal(long threadId) { 
    // 新建一个ExpirationEntry记录线程重入计数 
    ExpirationEntry entry = new ExpirationEntry(); 
    ExpirationEntry oldEntry = EXPIRATION_RENEWAL_MAP.putIfAbsent(getEntryName(), entry); 
    if (oldEntry != null) { 
        // 当前进行的当前线程重入加锁 
        oldEntry.addThreadId(threadId); 
    } else { 
        // 当前进行的当前线程首次加锁 
        entry.addThreadId(threadId); 
        // 首次新建ExpirationEntry需要触发续期方法，记录续期的任务句柄 
        renewExpiration(); 
    } 
} 
 
// 处理续期 
private void renewExpiration() { 
  // 根据entryName获取ExpirationEntry实例，如果为空，说明在cancelExpirationRenewal()方法已经被移除，一般是解锁的时候触发 
  ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName()); 
  if (ee == null) { 
    return; 
  } 
 
  // 新建一个定时任务，这个就是看门狗的实现，io.netty.util.Timeout是Netty结合时间轮使用的定时任务实例 
  Timeout task = commandExecutor.getConnectionManager().newTimeout(new TimerTask() { 
    @Override 
    public void run(Timeout timeout) throws Exception { 
      // 这里是重复外面的那个逻辑， 
      ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName()); 
      if (ent == null) { 
        return; 
      } 
      // 获取ExpirationEntry中首个线程ID，如果为空说明调用过cancelExpirationRenewal()方法清空持有的线程重入计数，一般是锁已经释放的场景 
      Long threadId = ent.getFirstThreadId(); 
      if (threadId == null) { 
        return; 
      } 
      // 向Redis异步发送续期的命令 
      RFuture<Boolean> future = renewExpirationAsync(threadId); 
      future.onComplete((res, e) -> { 
        // 抛出异常，续期失败，只打印日志和直接终止任务 
        if (e != null) { 
          log.error("Can't update lock " + getRawName() + " expiration", e); 
          EXPIRATION_RENEWAL_MAP.remove(getEntryName()); 
          return; 
        } 
        // 返回true证明续期成功，则递归调用续期方法（重新调度自己），续期失败说明对应的锁已经不存在，直接返回，不再递归 
        if (res) { 
          // reschedule itself 
          renewExpiration(); 
        } else { 
          cancelExpirationRenewal(null); 
        } 
      }); 
    }// 这里的执行频率为leaseTime转换为ms单位下的三分之一，由于leaseTime初始值为-1的情况下才会进入续期逻辑，那么这里的执行频率为lockWatchdogTimeout的三分之一 
  }, internalLockLeaseTime / 3, TimeUnit.MILLISECONDS); 
  // ExpirationEntry实例持有调度任务实例 
  ee.setTimeout(task); 
}
```

**核心点2-订阅解锁消息：RedissonLock.subscribe**



```java
protected final LockPubSub pubSub; 
 
public RedissonLock(CommandAsyncExecutor commandExecutor, String name) { 
  super(commandExecutor, name); 
  this.commandExecutor = commandExecutor; 
  this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(); 
  //在构造器中初始化pubSub,跟着这几个get方法会发现他们都是在构造器中初始化的，在PublishSubscribeService中会有 
  // private final AsyncSemaphore[] locks = new AsyncSemaphore[50]; 这样一段代码，初始化了一组信号量 
  this.pubSub = commandExecutor.getConnectionManager().getSubscribeService().getLockPubSub(); 
} 
 
protected RFuture<RedissonLockEntry> subscribe(long threadId) { 
  return pubSub.subscribe(getEntryName(), getChannelName()); 
} 
 
// 在LockPubSub中注册一个entryName -> RedissonLockEntry的哈希映射，RedissonLockEntry实例中存放着RPromise<RedissonLockEntry>结果，一个信号量形式的锁和订阅方法重入计数器 
public RFuture<E> subscribe(String entryName, String channelName) { 
  AsyncSemaphore semaphore = service.getSemaphore(new ChannelName(channelName)); 
  RPromise<E> newPromise = new RedissonPromise<>(); 
  semaphore.acquire(() -> { 
    if (!newPromise.setUncancellable()) { 
      semaphore.release(); 
      return; 
    } 
 
    E entry = entries.get(entryName); 
    if (entry != null) { 
      entry.acquire(); 
      semaphore.release(); 
      entry.getPromise().onComplete(new TransferListener<E>(newPromise)); 
      return; 
    } 
 
    E value = createEntry(newPromise); 
    value.acquire(); 
 
    E oldValue = entries.putIfAbsent(entryName, value); 
    if (oldValue != null) { 
      oldValue.acquire(); 
      semaphore.release(); 
      oldValue.getPromise().onComplete(new TransferListener<E>(newPromise)); 
      return; 
    } 
 
    RedisPubSubListener<Object> listener = createListener(channelName, value); 
    service.subscribe(LongCodec.INSTANCE, channelName, semaphore, listener); 
  }); 
 
  return newPromise; 
}
```

核心点 3 比较简单，就不说了

**解锁**

**RedissonLock.unlock()**



```java
@Override 
public void unlock() { 
  try { 
    // 获取当前调用解锁操作的线程ID 
    get(unlockAsync(Thread.currentThread().getId())); 
  } catch (RedisException e) { 
    // IllegalMonitorStateException一般是A线程加锁，B线程解锁，内部判断线程状态不一致抛出的 
    if (e.getCause() instanceof IllegalMonitorStateException) { 
      throw (IllegalMonitorStateException) e.getCause(); 
    } else { 
      throw e; 
    } 
  } 
}
```

**RedissonBaseLock.unlockAsync**



```java
@Override 
public RFuture<Void> unlockAsync(long threadId) { 
  // 构建一个结果RedissonPromise 
  RPromise<Void> result = new RedissonPromise<>(); 
  // 返回的RFuture如果持有的结果为true，说明解锁成功，返回NULL说明线程ID异常，加锁和解锁的客户端线程不是同一个线程 
  RFuture<Boolean> future = unlockInnerAsync(threadId); 
 
  future.onComplete((opStatus, e) -> { 
    // 取消看门狗的续期任务 
    cancelExpirationRenewal(threadId); 
 
    if (e != null) { 
      result.tryFailure(e); 
      return; 
    } 
 
    if (opStatus == null) { 
      IllegalMonitorStateException cause = new IllegalMonitorStateException("attempt to unlock lock, not locked by current thread by node id: " 
                                                                            + id + " thread-id: " + threadId); 
      result.tryFailure(cause); 
      return; 
    } 
 
    result.trySuccess(null); 
  }); 
 
  return result; 
}
```

**RedissonLock.unlockInnerAsync**



```java
// 真正的内部解锁的方法，执行解锁的Lua脚本 
protected RFuture<Boolean> unlockInnerAsync(long threadId) { 
  return evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN, 
                        //如果分布式锁存在，但是value不匹配，表示锁已经被其他线程占用，无权释放锁，那么直接返回空值（解铃还须系铃人） 
                        "if (redis.call('hexists', KEYS[1], ARGV[3]) == 0) then " + 
                        "return nil;" + 
                        "end; " + 
                        //如果value匹配，则就是当前线程占有分布式锁，那么将重入次数减1 
                        "local counter = redis.call('hincrby', KEYS[1], ARGV[3], -1); " + 
                        //重入次数减1后的值如果大于0，表示分布式锁有重入过，那么只能更新失效时间，还不能删除 
                        "if (counter > 0) then " + 
                        "redis.call('pexpire', KEYS[1], ARGV[2]); " + 
                        "return 0; " + 
                        "else " + 
                        //重入次数减1后的值如果为0，这时就可以删除这个KEY，并发布解锁消息，返回1 
                        "redis.call('del', KEYS[1]); " + 
                        "redis.call('publish', KEYS[2], ARGV[1]); " + 
                        "return 1; " + 
                        "end; " + 
                        "return nil;", 
                        //这5个参数分别对应KEYS[1]，KEYS[2]，ARGV[1]，ARGV[2]和ARGV[3] 
                        Arrays.asList(getRawName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId)); 
}
```

我只列出了一小部分代码，更多的内容还是得自己动手

从源码中，我们可以看到 Redisson 帮我们解决了抛出的第一个问题：失效时间设置多长时间为好?

Redisson 提供了看门狗，每获得一个锁时，只设置一个很短的超时时间，同时起一个线程在每次快要到超时时间时去刷新锁的超时时间。在释放锁的同时结束这个线程。

但是没有解决节点挂掉，丢失锁的问题，接着来~

### 四、RedLock

我们上边介绍的分布式锁，在某些极端情况下仍然是有缺陷的

**客户端长时间内阻塞导致锁失效**

客户端 1 得到了锁，因为网络问题或者 GC 等原因导致长时间阻塞，然后业务程序还没执行完锁就过期了，这时候客户端 2 也能正常拿到锁，可能会导致线程安全的问题。

**Redis 服务器时钟漂移**

如果 Redis 服务器的机器时间发生了向前跳跃，就会导致这个 key 过早超时失效，比如说客户端 1 拿到锁后，key 还没有到过期时间，但是 Redis 服务器的时间比客户端快了 2 分钟，导致 key 提前就失效了，这时候，如果客户端 1 还没有释放锁的话，就可能导致多个客户端同时持有同一把锁的问题。

**单点实例安全问题**

如果 Redis 是单机模式的，如果挂了的话，那所有的客户端都获取不到锁了，假设你是主从模式，但 Redis 的主从同步是异步进行的，如果 Redis 主宕机了，这个时候从机并没有同步到这一把锁，那么机器 B 再次申请的时候就会再次申请到这把锁，这也是问题

为了解决这些个问题 Redis 作者提出了 RedLock 红锁的算法，在 Redission 中也对 RedLock 进行了实现。

Redis 官网对 redLock 算法的介绍大致如下：The Redlock algorithm

在分布式版本的算法里我们假设我们有 N 个 Redis master 节点，这些节点都是完全独立的，我们不用任何或者其他隐含的分布式协调机制。之前我们已经描述了在 Redis 单实例下怎么安全地获取和释放锁。我们确保将在每(N) 个实例上使用此方法获取和释放锁。在我们的例子里面我们设置 N=5，这是一个比较合理的设置，所以我们需要在 5 台机器或者虚拟机上面运行这些实例，这样保证他们不会同时都宕掉。为了取到锁，客户端应该执行以下操作:

获取当前 Unix 时间，以毫秒为单位。

依次尝试从 5 个实例，使用相同的 key 和具有唯一性的 value(例如UUID)获取锁。当向 Redis 请求获取锁时，客户端应该设置一个尝试从某个 Reids 实例获取锁的最大等待时间(超过这个时间，则立马询问下一个实例)，这个超时时间应该小于锁的失效时间。例如你的锁自动失效时间为 10 秒，则超时时间应该在 5-50 毫秒之间。这样可以避免服务器端 Redis 已经挂掉的情况下，客户端还在死死地等待响应结果。如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个 Redis 实例请求获取锁。

客户端使用当前时间减去开始获取锁时间(步骤1记录的时间)就得到获取锁消耗的时间。当且仅当从大多数(N/2+1，这里是3个节点)的 Redis 节点都取到锁，并且使用的总耗时小于锁失效时间时，锁才算获取成功。

如果取到了锁，key 的真正有效时间 = 有效时间(获取锁时设置的 key 的自动超时时间) - 获取锁的总耗时(询问各个 Redis 实例的总耗时之和)(步骤 3 计算的结果)。

如果因为某些原因，最终获取锁失败(即没有在至少 “N/2+1 ”个 Redis 实例取到锁或者“获取锁的总耗时”超过了“有效时间”)，客户端应该在所有的 Redis 实例上进行解锁(即便某些 Redis 实例根本就没有加锁成功，这样可以防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁)。

总结下就是：

客户端在多个 Redis 实例上申请加锁，必须保证大多数节点加锁成功

解决容错性问题，部分实例异常，剩下的还能加锁成功

大多数节点加锁的总耗时，要小于锁设置的过期时间

多实例操作，可能存在网络延迟、丢包、超时等问题，所以就算是大多数节点加锁成功，如果加锁的累积耗时超过了锁的过期时间，那有些节点上的锁可能也已经失效了，还是没有意义的

释放锁，要向全部节点发起释放锁请求

如果部分节点加锁成功，但最后由于异常导致大部分节点没加锁成功，就要释放掉所有的，各节点要保持一致

关于 RedLock，两位分布式大佬，Antirez 和 Martin 还进行过一场争论，感兴趣的也可以看看



```java
Config config1 = new Config(); 
config1.useSingleServer().setAddress("127.0.0.1:6379"); 
RedissonClient redissonClient1 = Redisson.create(config1); 
 
Config config2 = new Config(); 
config2.useSingleServer().setAddress("127.0.0.1:5378"); 
RedissonClient redissonClient2 = Redisson.create(config2); 
 
Config config3 = new Config(); 
config3.useSingleServer().setAddress("127.0.0.1:5379"); 
RedissonClient redissonClient3 = Redisson.create(config3); 
 
/** 
 * 获取多个 RLock 对象 
 */ 
RLock lock1 = redissonClient1.getLock(lockKey); 
RLock lock2 = redissonClient2.getLock(lockKey); 
RLock lock3 = redissonClient3.getLock(lockKey); 
 
/** 
 * 根据多个 RLock 对象构建 RedissonRedLock （最核心的差别就在这里） 
 */ 
RedissonRedLock redLock = new RedissonRedLock(lock1, lock2, lock3); 
 
try { 
    /** 
     * 4.尝试获取锁 
     * waitTimeout 尝试获取锁的最大等待时间，超过这个值，则认为获取锁失败 
     * leaseTime   锁的持有时间,超过这个时间锁会自动失效（值应设置为大于业务处理的时间，确保在锁有效期内业务能处理完） 
     */ 
    boolean res = redLock.tryLock(100, 10, TimeUnit.SECONDS); 
    if (res) { 
        //成功获得锁，在这里处理业务 
    } 
} catch (Exception e) { 
    throw new RuntimeException("aquire lock fail"); 
}finally{ 
    //无论如何, 最后都要解锁 
    redLock.unlock(); 
}
```

最核心的变化就是需要构建多个 RLock ，然后根据多个 RLock 构建成一个 RedissonRedLock，因为 redLock 算法是建立在多个互相独立的 Redis 环境之上的(为了区分可以叫为 Redission node)，Redission node 节点既可以是单机模式(single)，也可以是主从模式(master/salve)，哨兵模式(sentinal)，或者集群模式(cluster)。这就意味着，不能跟以往这样只搭建 1个 cluster、或 1个 sentinel 集群，或是1套主从架构就了事了，需要为 RedissonRedLock 额外搭建多几套独立的 Redission 节点。

**RedissonMultiLock.tryLock**



```java
@Override 
public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit) throws InterruptedException { 
  //        try { 
  //            return tryLockAsync(waitTime, leaseTime, unit).get(); 
  //        } catch (ExecutionException e) { 
  //            throw new IllegalStateException(e); 
  //        } 
  long newLeaseTime = -1; 
  if (leaseTime != -1) { 
    if (waitTime == -1) { 
      newLeaseTime = unit.toMillis(leaseTime); 
    } else { 
      newLeaseTime = unit.toMillis(waitTime)*2; 
    } 
  } 
 
  long time = System.currentTimeMillis(); 
  long remainTime = -1; 
  if (waitTime != -1) { 
    remainTime = unit.toMillis(waitTime); 
  } 
  long lockWaitTime = calcLockWaitTime(remainTime); 
 
  //允许加锁失败节点个数限制（N-(N/2+1)） 
  int failedLocksLimit = failedLocksLimit(); 
  List<RLock> acquiredLocks = new ArrayList<>(locks.size()); 
  // 遍历所有节点通过EVAL命令执行lua加锁 
  for (ListIterator<RLock> iterator = locks.listIterator(); iterator.hasNext();) { 
    RLock lock = iterator.next(); 
    boolean lockAcquired; 
    try { 
      // 对节点尝试加锁 
      if (waitTime == -1 && leaseTime == -1) { 
        lockAcquired = lock.tryLock(); 
      } else { 
        long awaitTime = Math.min(lockWaitTime, remainTime); 
        lockAcquired = lock.tryLock(awaitTime, newLeaseTime, TimeUnit.MILLISECONDS); 
      } 
    } catch (RedisResponseTimeoutException e) { 
      // 如果抛出这类异常，为了防止加锁成功，但是响应失败，需要解锁所有节点 
      unlockInner(Arrays.asList(lock)); 
      lockAcquired = false; 
    } catch (Exception e) { 
      lockAcquired = false; 
    } 
 
    if (lockAcquired) { 
      acquiredLocks.add(lock); 
    } else { 
      /* 
       *  计算已经申请锁失败的节点是否已经到达 允许加锁失败节点个数限制 （N-(N/2+1)） 
       * 如果已经到达， 就认定最终申请锁失败，则没有必要继续从后面的节点申请了 
       * 因为 Redlock 算法要求至少N/2+1 个节点都加锁成功，才算最终的锁申请成功 
       */ 
      if (locks.size() - acquiredLocks.size() == failedLocksLimit()) { 
        break; 
      } 
 
      if (failedLocksLimit == 0) { 
        unlockInner(acquiredLocks); 
        if (waitTime == -1) { 
          return false; 
        } 
        failedLocksLimit = failedLocksLimit(); 
        acquiredLocks.clear(); 
        // reset iterator 
        while (iterator.hasPrevious()) { 
          iterator.previous(); 
        } 
      } else { 
        failedLocksLimit--; 
      } 
    } 
    //计算 目前从各个节点获取锁已经消耗的总时间，如果已经等于最大等待时间，则认定最终申请锁失败，返回false 
    if (remainTime != -1) { 
      remainTime -= System.currentTimeMillis() - time; 
      time = System.currentTimeMillis(); 
      if (remainTime <= 0) { 
        unlockInner(acquiredLocks); 
        return false; 
      } 
    } 
  } 
 
  if (leaseTime != -1) { 
    acquiredLocks.stream() 
      .map(l -> (RedissonLock) l) 
      .map(l -> l.expireAsync(unit.toMillis(leaseTime), TimeUnit.MILLISECONDS)) 
      .forEach(f -> f.syncUninterruptibly()); 
  } 
 
  return true; 
}
```

# Redis线程模型

> redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫做单线程的模型。
>
> 它采用 IO 多路复用机制同时监听多个 socket，根据 socket 上的事件来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

- **多个 socket**
- **IO 多路复用程序**
- **文件事件分派器**
- **事件处理器（包括：连接应答处理器、命令请求处理器、命令回复处理器）**

多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 [IO 多路复用](https://www.wylong.top/netty/03-网络IO模型讲解.html) 程序会监听多个 socket，会将 socket 产生的事件放入队列中排队，事件分派器每次从队列中取出一个事件，把该事件交给对应的事件处理器进行处理。

来看客户端与 redis 的一次通信过程：

![img](redis-intro/17-redis线程模型.png)

1. 客户端 socket01 向 redis 的 server socket 请求建立连接，此时 server socket 会产生一个 AE_READABLE 事件，IO 多路复用程序监听到 server socket 产生的事件后，将该事件压入队列中。文件事件分派器从队列中获取该事件，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的 socket01，并将该 socket01 的 AE_READABLE 事件与命令请求处理器关联。
2. 假设此时客户端发送了一个 set key value 请求，此时 redis 中的 socket01 会产生 AE_READABLE 事件，IO 多路复用程序将事件压入队列，此时事件分派器从队列中获取到该事件，由于前面 socket01 的 AE_READABLE 事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取 socket01 的 key value 并在自己内存中完成 key value 的设置。操作完成后，它会将 socket01 的 AE_WRITABLE 事件与命令回复处理器关联。
3. 如果此时客户端准备好接收返回结果了，那么 redis 中的 socket01 会产生一个 AE_WRITABLE 事件，同样压入队列中，事件分派器找到相关联的命令回复处理器，由命令回复处理器对 socket01 输入本次操作的一个结果，比如 ok，之后解除 socket01 的 AE_WRITABLE 事件与命令回复处理器的关联。

这样便完成了一次通信。

## 为啥 redis 单线程模型也能效率这么高？

- **纯内存操作**
- **核心是基于非阻塞的 IO 多路复用机制**
- **单线程反而避免了多线程的频繁上下文切换问题**

#  Redis缓存击穿、雪崩、穿透的解决方案

### 概念简述

- 缓存击穿
  - 某个热点key缓存失效了
- 缓存雪崩
  - 多个热点key都过期
- 缓存穿透
  - 查询不存在数据

### 缓存击穿+解决方案

- 缓存击穿 (某个热点key缓存失效了)

  - 缓存中没有但数据库中有的数据，假如是热点数据，那key在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力增大。
  - 和缓存雪崩的区别在于这里针对某一key缓存，后者则是很多key。

- 预防

  - 设置热点数据不过期
  - 定时任务定时更新缓存
  - 设置互斥锁

- SpringCache解决方案

  - 缓存的同步 sync
  - sync 可以指示底层将缓存锁住，使只有一个线程可以进入计算，而其他线程堵塞，直到返回结果更新到缓存中

  ```java
  @Cacheable(value = {"product"},key = "#root.args[0]", cacheManager = "customCacheManager", sync=true)
  ```

### 缓存雪崩+解决方案

- 缓存雪崩 (多个热点key都过期)

  - 大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩

  - 预防

    - 存数据的过期时间设置随机，防止同一时间大量数据过期现象发生
    - 设置热点数据永远不过期，定时任务定时更新

  - SpringCache解决方案

    - 设置差别的过时时间
    - 比如CacheManager配置多个过期时间维度
    - 配置文件 time-to-live 配置

    ```yaml
     cache:
       #使用的缓存类型
        type: redis
       #过时时间
        redis:
          time-to-live: 3600000
          # 开启前缀，默以为true
          use-key-prefix: true
          # 键的前缀,默认就是缓存名cacheNames
          key-prefix: WYL_CACHE
          # 是否缓存空结果，防止缓存穿透，默以为true
          cache-null-values: true
    ```

### 缓存穿透+解决方案

- 缓存穿透（查询不存在数据）

  - 查询一个不存在的数据，由于缓存是不命中的，并且出于容错考虑，如发起为id为“-1”不存在的数据

  - 如果从存储层查不到数据则不写入缓存这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。存在大量查询不存在的数据，可能DB就挂掉了，这也是黑客利用不存在的key频繁攻击应用的一种方式。

  - 预防

    - 接口层增加校验，数据合理性校验
    - 缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，设置短点的过期时间，防止同个key被一直攻击

  - 使用布隆过滤器解决

    将已存在的缓存到布隆过滤器中，当访问不存在的缓存时迅速返回避免缓存及DB挂掉

    > 并不能完全解决， 只能将其控制在一个可以容忍的范围内

  - SpringCache解决方案

    - 空结果也缓存，默认不配置condition或者unless就行

    ```yaml
    cache:
       #使用的缓存类型
        type: redis
       #过时时间
        redis:
          time-to-live: 3600000
          # 开启前缀，默以为true
          use-key-prefix: true
          # 键的前缀,默认就是缓存名cacheNames
          key-prefix: WYL
          # 是否缓存空结果，防止缓存穿透，默以为true
          cache-null-values: true
    ```

## 布隆过滤器

### 寻衅滋事？先过了我这道关

**简介：布隆过滤器是什么，一定要用吗?**

> 解决缓存穿透

- 黑客流量攻击：故意访问不存在的数据，导致程序不断访问DB数据库的数据
- 黑客安全阻截：当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉
- 思考：如果让你实现这个功能你会怎么做？ key：10000 10001 10002 10003 大集合，key是否在集合里面
- 温故而知新：分析java常用数据结构复习
  - list.contain (key)遍历数据，进行equals()比较，性能小
  - set.contain(key) hashcode比较，性能较高，一个key,64位 1千万数据量就是1G
  - map.get(key) hashcode比较，性能还行
- 概念：
  - **布隆过滤器**（英语：Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的[二进制](https://zh.wikipedia.org/wiki/二进制)向量和一系列随机[映射函数](https://zh.wikipedia.org/wiki/映射)。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都远远超过一般的算法，缺点是有一定的误识别率和删除困难。
- 优点:
  - 相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数。另外，散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势
- 缺点
  - 但是布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。

![img](redis-intro/14-布隆过滤器1.png)

------

### 布隆过滤器原理

布隆过滤器原理：

我们可以把它看做一个会产生误判并且占用空间极少的HashSet。它的结构是一个Bit数组（数组中每个位置只占用一个bit，每个bit位有0和1两种状态）和一系列Hash函数的集合，我们将输入域通过上述一系列Hash函数进行Hash运算得到n个key值，将这n个值对数组的长度进行取余，然后将bit数组中对应的位置bit位设为1。在数组足够大，hash碰撞足够小的情况下，每个输入域都会在数组中不同的位置将其bit位置为1，我们把集合中所有的元素都按照这个方式来一遍的话一个布隆过滤器就生成好了。

那么如何判断一个元素是否在布隆过滤器中呢，原理和生成布隆过滤器的过程差不多，我们将要判断的值通过布隆过滤器的n个Hash函数计算出n个值，对数组长度取余得到bit数组中n个位置，接下来判断这n个位置的bit位是否都为1，若都为1，则说明该元素在集合中，若有一个为0，则该元素肯定不在集合中。

![img](redis-intro/14-布隆过滤器实现原理.png)

- 那么这个布隆过滤器就有这么几个特点：

  1. 空间占用小

  2. 查询效率高

  3. 有一定误判率：一定不存在，可能存在

     - 返回数据不存在，则肯定不存在。
     - 返回数据存在，但只能是大概率存在。

  4. 删除问题：

     目前我们知道布隆过滤器可以支持 add 和 isExist 操作，那么 delete 操作可以么，答案是不可以，例如上图中的 bit 位 4 被两个值共同覆盖的话，一旦你删除其中一个值例如 “tencent” 而将其置位 0，那么下次判断另一个值例如 “baidu” 是否存在的话，会直接返回 false，而实际上你并没有删除它。

- 布隆过滤器的其他使用场景

  - 网页爬虫对URL的去重，避免爬取相同的URL地址

  - 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）

  - 解决**缓存穿透**，将已存在的缓存放到布隆中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉

    并不能完全解决， 只能将其控制在一个可以容忍的范围内

------

### 谷歌布隆过滤器实现会员转盘抽奖

**简介：抽奖程序功能需求分析，谷歌实现布隆过滤器，谷歌布隆过滤器的局限性**

- 需求分析步骤

  - 互联网功能需求分析
    - 这是一个抽奖程序，只针对会员用户有效
  - 抽离出功能所有api
  - 制定存储方案
  - 性能优化方案分析

  

- 成型互联网产品用户量上千万，日常百万，怎么做到高性能非会员过滤

- 这是一个布隆过滤器的经典使用场景

- 通过google布隆过滤器存储会员数据实战

  - 程序启动时将数据放入内存中
  - google自动创建布隆过滤器
  - 用户ID进来之后判断是否是会员

- 设计表

  ```sql
  CREATE TABLE `sys_user` (
    `id` int(11) unsigned NOT NULL AUTO_INCREMENT,
    `user_name` varchar(11) CHARACTER SET utf8mb4 DEFAULT NULL COMMENT '用户名',
    `image` varchar(11) CHARACTER SET utf8mb4 DEFAULT NULL COMMENT '用户头像',
    PRIMARY KEY (`id`)
  ) ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=utf8;
  ```

主要代码示例：

```java
import com.google.common.hash.BloomFilter;
import com.google.common.hash.Funnels;
import org.springframework.stereotype.Service;
import org.springframework.util.CollectionUtils;

import javax.annotation.PostConstruct;
import javax.annotation.Resource;
import java.util.List;

@Service
public class BloomFilterService {

    @Resource
    private SysUserMapper sysUserMapper;

    private BloomFilter<Integer> bf;

    /***
     * PostConstruct 程序启动时候加载此方法
     */
    @PostConstruct
    public void initBloomFilter() {
        SysUserExample sysUserExample = new SysUserExample();
        List<SysUser> sysUserList = sysUserMapper.selectByExample(sysUserExample);
        if(CollectionUtils.isEmpty(sysUserList)){
            return;
        }
        //创建布隆过滤器(默认3%误差)
        bf = BloomFilter.create(Funnels.integerFunnel(),sysUserList.size());
        for (SysUser sysUser:sysUserList) {
            bf.put(sysUser.getId());
        }
    }

    /***
     * 判断id可能存在于布隆过滤器里面
     * @param id
     * @return
     */
    public boolean userIdExists(int id){
        return bf.mightContain(id);
    }
}
```

------

### goole布隆过滤器与Redis布隆过滤器

**简介：**布隆过滤器两种实现方案的优缺点分析

- google布隆过滤器的缺陷与思考

  - 基于内存布隆过滤器有什么特点
  - 内存级别产物
  - 重启即失效
  - 本地内存无法用在分布式场景
  - 不支持大数据量存储

- 需求分析步骤

  - 互联网功能需求分析
    - 这是一个抽奖程序，只针对会员用户有效
  - 抽离出功能所有api
  - 制定存储方案
  - 性能优化方案分析

  

- Redis布隆过滤器

  - 可扩展性Bloom过滤器
    - 一旦Bloom过滤器达到容量，就会在其上创建一个新的过滤器
  - 不存在重启即失效或者定时任务维护的成本
    - 基于goole实现的布隆过滤器需要启动之后初始化布隆过滤器
  - 缺点：
    - 需要网络IO,性能比基于内存的过滤器低

- 选择:

  优先基于数据量进行考虑

------

### Redis布隆过滤器安装

**centos7下安装**

- 下载并编译模块：

  ```shell
  # 下载并上传到服务器，下载地址
  https://github.com/RedisBloom/RedisBloom
  # 解压
  unzip RedisBloom-master.zip
  # 进入目录
  cd RedisBloom-master
  # 编译
  make
  # 目录下生成文件
  redisbloom.so
  # 拷贝目录下生成的文件redisbloom.so到redis的bin目录下
  cp redisbloom.so /usr/local/redis/bin/redisbloom.so
  ```

- redis引入该模块

  ```shell
  # 在redis.conf配置文件里加入如下引入配置
  loadmodule /usr/local/redis/bin/redisbloom.so
  # redis集群每个配置文件都需要加入这一行
  ```

- 重启redis

  ```
  ./redis-cli shutdown
  ./redis-server redis.conf
  ```

- 命令实战

  ```shell
  127.0.0.1:6379> bf.add codehole user1
  (integer) 1
  127.0.0.1:6379> bf.add codehole user2
  (integer) 1
  127.0.0.1:6379> bf.add codehole user3
  (integer) 1
  127.0.0.1:6379> bf.exists codehole user1
  (integer) 1
  127.0.0.1:6379> bf.exists codehole user2
  (integer) 1
  127.0.0.1:6379> bf.exists codehole user3
  (integer) 1
  127.0.0.1:6379> bf.exists codehole user4
  (integer) 0
  127.0.0.1:6379> bf.madd codehole user4 user5 user6
  1) (integer) 1
  2) (integer) 1
  3) (integer) 1
  127.0.0.1:6379> bf.mexists codehole user4 user5 user6 user7
  1) (integer) 1
  2) (integer) 1
  3) (integer) 1
  4) (integer) 0
  ```

------

### Redis布隆过滤器与springboot的整合

**基于lua脚本实现springboot和布隆过滤器的整合**

- 通过普通命令无法实现springboot整合布隆过滤器
- 查找github开源框架的流程
- 分析开源框架的实现原理
- 通过lua脚本自己实现布隆过滤器
- 编写两个lua脚本
  - 添加数据到指定名称的布隆过滤器
  - 从指定名称的布隆过滤器获取key是否存在的脚本

```
bloomFilterAdd.lua
local bloomName = KEYS[1]
local value = KEYS[2]

-- bloomFilter
local result_1 = redis.call('BF.ADD', bloomName, value)
return result_1
bloomFilterExist.lua
local bloomName = KEYS[1]
local value = KEYS[2]

-- bloomFilter
local result_1 = redis.call('BF.EXISTS', bloomName, value)
return result_1
```

java代码调用：

```java
    public Boolean bloomFilterAdd(String filterName,int value){
        DefaultRedisScript<Boolean> bloomAdd = new DefaultRedisScript<>();
        bloomAdd.setScriptSource(new ResourceScriptSource(new ClassPathResource("bloomFilterAdd.lua")));
        bloomAdd.setResultType(Boolean.class);
        List<Object> keyList= new ArrayList<>();
        keyList.add(filterName);
        keyList.add(value+"");
        Boolean result = (Boolean) redisTemplate.execute(bloomAdd,keyList);
        return result;
    }



    public Boolean bloomFilterExists(String filterName,int value){
        DefaultRedisScript<Boolean> bloomExists= new DefaultRedisScript<>();
        bloomExists.setScriptSource(new ResourceScriptSource(new ClassPathResource("bloomFilterExist.lua")));
        bloomExists.setResultType(Boolean.class);
        List<Object> keyList= new ArrayList<>();
        keyList.add(filterName);
        keyList.add(value+"");
        Boolean result = (Boolean) redisTemplate.execute(bloomExists,keyList);
        return result;
    }
```
